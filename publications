@article{bruhlmann2020trustdiff,
  title={TrustDiff: Development and Validation of a Semantic Differential for User Trust on the Web},
  author={Brühlmann, Florian and Petralito, Serge and Rieser, Denise C. and Aeschbach, Lena F. and Opwis, Klaus},
  journal={Journal of Usability Studies},
  volume={16},
  number={1},
  pages={29--48},
  year={2020},
  URL = {https://uxpajournal.org/trustdiff-semantic-differential-for-user-trust-web/}
}


@article{doi:10.1177/2515245920958687,
 abstract = { Replication studies in psychological science sometimes fail to reproduce prior findings. If these studies use methods that are unfaithful to the original study or ineffective in eliciting the phenomenon of interest, then a failure to replicate may be a failure of the protocol rather than a challenge to the original finding. Formal pre-data-collection peer review by experts may address shortcomings and increase replicability rates. We selected 10 replication studies from the Reproducibility Project: Psychology (RP:P; Open Science Collaboration, 2015) for which the original authors had expressed concerns about the replication designs before data collection; only one of these studies had yielded a statistically significant effect (p < .05). Commenters suggested that lack of adherence to expert review and low-powered tests were the reasons that most of these RP:P studies failed to replicate the original effects. We revised the replication protocols and received formal peer review prior to conducting new replication studies. We administered the RP:P and revised protocols in multiple laboratories (median number of laboratories per original study = 6.5, range = 3–9; median total sample = 1,279.5, range = 276–3,512) for high-powered tests of each original finding with both protocols. Overall, following the preregistered analysis plan, we found that the revised protocols produced effect sizes similar to those of the RP:P protocols (Δr = .002 or .014, depending on analytic approach). The median effect size for the revised protocols (r = .05) was similar to that of the RP:P protocols (r = .04) and the original RP:P replications (r = .11), and smaller than that of the original studies (r = .37). Analysis of the cumulative evidence across the original studies and the corresponding three replication attempts provided very precise estimates of the 10 tested effects and indicated that their effect sizes (median r = .07, range = .00–.15) were 78% smaller, on average, than the original effect sizes (median r = .37, range = .19–.50). },
 author = {Charles R. Ebersole and Maya B. Mathur and Erica Baranski and Diane-Jo Bart-Plange and Nicholas R. Buttrick and Christopher R. Chartier and Katherine S. Corker and Martin Corley and Joshua K. Hartshorne and Hans IJzerman and Ljiljana B. Lazarević and Hugh Rabagliati and Ivan Ropovik and Balazs Aczel and Lena F. Aeschbach and Luca Andrighetto and Jack D. Arnal and Holly Arrow and Peter Babincak and Bence E. Bakos and Gabriel Baník and Ernest Baskin and Radomir Belopavlović and Michael H. Bernstein and Michał Białek and Nicholas G. Bloxsom and Bojana Bodroža and Diane B. V. Bonfiglio and Leanne Boucher and Florian Brühlmann and Claudia C. Brumbaugh and Erica Casini and Yiling Chen and Carlo Chiorri and William J. Chopik and Oliver Christ and Antonia M. Ciunci and Heather M. Claypool and Sean Coary and Marija V. Čolić and W. Matthew Collins and Paul G. Curran and Chris R. Day and Benjamin Dering and Anna Dreber and John E. Edlund and Filipe Falcão and Anna Fedor and Lily Feinberg and Ian R. Ferguson and Máire Ford and Michael C. Frank and Emily Fryberger and Alexander Garinther and Katarzyna Gawryluk and Kayla Ashbaugh and Mauro Giacomantonio and Steffen R. Giessner and Jon E. Grahe and Rosanna E. Guadagno and Ewa Hałasa and Peter J. B. Hancock and Rias A. Hilliard and Joachim Hüffmeier and Sean Hughes and Katarzyna Idzikowska and Michael Inzlicht and Alan Jern and William Jiménez-Leal and Magnus Johannesson and Jennifer A. Joy-Gaba and Mathias Kauff and Danielle J. Kellier and Grecia Kessinger and Mallory C. Kidwell and Amanda M. Kimbrough and Josiah P. J. King and Vanessa S. Kolb and Sabina Kołodziej and Marton Kovacs and Karolina Krasuska and Sue Kraus and Lacy E. Krueger and Katarzyna Kuchno and Caio Ambrosio Lage and Eleanor V. Langford and Carmel A. Levitan and Tiago Jessé Souza de Lima and Hause Lin and Samuel Lins and Jia E. Loy and Dylan Manfredi and Łukasz Markiewicz and Madhavi Menon and Brett Mercier and Mitchell Metzger and Venus Meyet and Ailsa E. Millen and Jeremy K. Miller and Andres Montealegre and Don A. Moore and Rafał Muda and Gideon Nave and Austin Lee Nichols and Sarah A. Novak and Christian Nunnally and Ana Orlić and Anna Palinkas and Angelo Panno and Kimberly P. Parks and Ivana Pedović and Emilian Pękala and Matthew R. Penner and Sebastiaan Pessers and Boban Petrović and Thomas Pfeiffer and Damian Pieńkosz and Emanuele Preti and Danka Purić and Tiago Ramos and Jonathan Ravid and Timothy S. Razza and Katrin Rentzsch and Juliette Richetin and Sean C. Rife and Anna Dalla Rosa and Kaylis Hase Rudy and Janos Salamon and Blair Saunders and Przemysław Sawicki and Kathleen Schmidt and Kurt Schuepfer and Thomas Schultze and Stefan Schulz-Hardt and Astrid Schütz and Ani N. Shabazian and Rachel L. Shubella and Adam Siegel and Rúben Silva and Barbara Sioma and Lauren Skorb and Luana Elayne Cunha de Souza and Sara Steegen and L. A. R. Stein and R. Weylin Sternglanz and Darko Stojilović and Daniel Storage and Gavin Brent Sullivan and Barnabas Szaszi and Peter Szecsi and Orsolya Szöke and Attila Szuts and Manuela Thomae and Natasha D. Tidwell and Carly Tocco and Ann-Kathrin Torka and Francis Tuerlinckx and Wolf Vanpaemel and Leigh Ann Vaughn and Michelangelo Vianello and Domenico Viganola and Maria Vlachou and Ryan J. Walker and Sophia C. Weissgerber and Aaron L. Wichman and Bradford J. Wiggins and Daniel Wolf and Michael J. Wood and David Zealley and Iris Žeželj and Mark Zrubka and Brian A. Nosek},
 doi = {10.1177/2515245920958687},
 eprint = { 
https://doi.org/10.1177/2515245920958687
},
 journal = {Advances in Methods and Practices in Psychological Science},
 number = {3},
 pages = {309-331},
 title = {Many Labs 5: Testing Pre-Data-Collection Peer Review as an Intervention to Increase Replicability},
 url = { 
https://doi.org/10.1177/2515245920958687
},
 volume = {3},
 year = {2020}
}



@article{doi:10.1177/2515245920917931,
 abstract = { Does convincing people that free will is an illusion reduce their sense of personal responsibility? Vohs and Schooler (2008) found that participants reading from a passage “debunking” free will cheated more on experimental tasks than did those reading from a control passage, an effect mediated by decreased belief in free will. However, this finding was not replicated by Embley, Johnson, and Giner-Sorolla (2015), who found that reading arguments against free will had no effect on cheating in their sample. The present study investigated whether hard-to-understand arguments against free will and a low-reliability measure of free-will beliefs account for Embley et al.’s failure to replicate Vohs and Schooler’s results. Participants (N = 621) were randomly assigned to participate in either a close replication of Vohs and Schooler’s Experiment 1 based on the materials of Embley et al. or a revised protocol, which used an easier-to-understand free-will-belief manipulation and an improved instrument to measure free will. We found that the revisions did not matter. Although the revised measure of belief in free will had better reliability than the original measure, an analysis of the data from the two protocols combined indicated that free-will beliefs were unchanged by the manipulations, d = 0.064, 95% confidence interval = [−0.087, 0.22], and in the focal test, there were no differences in cheating behavior between conditions, d = 0.076, 95% CI = [−0.082, 0.22]. We found that expressed free-will beliefs did not mediate the link between the free-will-belief manipulation and cheating, and in exploratory follow-up analyses, we found that participants expressing lower beliefs in free will were not more likely to cheat in our task. },
 author = {Nicholas R. Buttrick and Balazs Aczel and Lena F. Aeschbach and Bence E. Bakos and Florian Brühlmann and Heather M. Claypool and Joachim Hüffmeier and Marton Kovacs and Kurt Schuepfer and Peter Szecsi and Attila Szuts and Orsolya Szöke and Manuela Thomae and Ann-Kathrin Torka and Ryan J. Walker and Michael J. Wood},
 doi = {10.1177/2515245920917931},
 eprint = { 
https://doi.org/10.1177/2515245920917931
},
 journal = {Advances in Methods and Practices in Psychological Science},
 number = {3},
 pages = {429-438},
 title = {Many Labs 5: Registered Replication of Vohs and Schooler (2008), Experiment 1},
 url = { 
https://doi.org/10.1177/2515245920917931
},
 volume = {3},
 year = {2020}
}



@inproceedings{vollenwyder2020my,
	location = {Cham},
	title = {My Train Talks to Me: Participatory Design of a Mobile App for Travellers with Visual Impairments},
	isbn = {978-3-030-58796-3},
	doi = {10.1007/978-3-030-58796-3_2},
	series = {Lecture Notes in Computer Science},
	shorttitle = {My Train Talks to Me},
	abstract = {Travellers with visual impairments may face substantial information gaps on their journeys by public transport. For instance, information displayed in trains, as well as on departure boards in train stations and on platforms, are often not available in acoustic or tactile form. Digital technologies, such as smartphones or smartwatches, can provide an alternative means of access. However, these alternatives do not guarantee that the user experience is comparable in value, quality and efficiency. The present case study details a participatory design process, where travellers with visual impairments co-designed a mobile app. The goal was to tackle information gaps on journeys by public transport and to learn how participatory design can facilitate the provision of comparable experiences for users with disabilities. Travellers with visual impairments were involved in a collaborative process in all project phases, including problem identification, technical feasibility, proof of concept, design and development. Participatory design contributed to a thorough understanding of the user perspective and allowed the app to be optimised for the needs of travellers with visual impairments. Furthermore, co-design proved to be an effective method for fostering awareness and knowledge about digital accessibility at all organisational levels.},
	pages = {10--18},
	booktitle = {Computers Helping People with Special Needs},
	publisher = {Springer International Publishing},
	author = {Vollenwyder, Beat and Buchmüller, Esther and Trachsel, Christian and Opwis, Klaus and Brühlmann, Florian},
	editor = {Miesenberger, Klaus and Manduchi, Roberto and Covarrubias Rodriguez, Mario and Peňáz, Petr},
	date = {2020},
	langid = {english},
	keywords = {Case study, Digital accessibility, Participatory design, People with visual impairments, User experience},
}



@InProceedings{10.1007/978-3-030-58796-3_35,
author="Vollenwyder, Beat
and Opwis, Klaus
and Br{\"u}hlmann, Florian",
editor="Miesenberger, Klaus
and Manduchi, Roberto
and Covarrubias Rodriguez, Mario
and Pe{\v{n}}{\'a}z, Petr",
title="How Web Professionals Perceive Web Accessibility in Practice: Active Roles, Process Phases and Key Disabilities",
booktitle="Computers Helping People with Special Needs",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="294--302",
abstract="Providing usable web information and services to as many people as possible confronts web professionals with a challenging task. The present study delivers insights about how Web accessibility is perceived in practice. Using a survey, a total of 163 web professionals in various roles reported their evaluation of Web accessibility implementation in their projects with regard to three aspects: the professional roles primarily responsible for Web accessibility, key phases in the development process, and the types of disabilities primarily considered. Results show that non-technical professional roles are perceived to be less involved in the development process, that Web accessibility considerations are mainly restricted to the design and implementation phases of projects, and that efforts focus predominantly on the needs of people with visual impairments.",
isbn="978-3-030-58796-3",
doi="10.1007/978-3-030-58796-3_35"
}



@article{10.3389/fpsyg.2020.01307,
 abstract = {Player motivation is a key research area within games research, with the aim of understanding how the motivation of players is related to their experience and behavior in the game. We present the results of a cross-sectional study with data from 750 players of League of Legends, a popular Multiplayer Online Battle Arena game. Based on the motivational regulations posited by Self-Determination Theory and Latent Profile Analysis, we identify four distinct motivational profiles, which differ with regards to player experience and, to a lesser extent, in-game behavior. While the more self-determined profiles “Intrinsic” and “Autonomous” report mainly positive experience-related outcomes, a considerable part of the player base does not. Players of the “Amotivated” and “External” profile derive less enjoyment, experience more negative affect and tension, and score lower on vitality, indicating game engagement that is potentially detrimental to players' well-being. With regards to game metrics, minor differences in the rate of assists in unranked matches and performance indicators were observed between profiles. This strengthens the notion that differences in experiences are not necessarily reflected in differences in behavioral game metrics. Our findings provide insights into the interplay of player motivation, experience, and in-game behavior, contributing to a more nuanced understanding of player-computer interaction.},
 author = {Brühlmann, Florian and Baumgartner, Philipp and Wallner, Günter and Kriglstein, Simone and Mekler, Elisa D.},
 doi = {10.3389/fpsyg.2020.01307},
 issn = {1664-1078},
 journal = {Frontiers in Psychology},
 pages = {1307},
 title = {Motivational Profiling of League of Legends Players},
 url = {https://www.frontiersin.org/article/10.3389/fpsyg.2020.01307},
 volume = {11},
 year = {2020}
}




@article{BRUHLMANN2020100022,
 abstract = {Despite recent concerns about data quality, various academic fields rely increasingly on crowdsourced samples. Thus, the goal of this study was to systematically assess carelessness in a crowdsourced sample (N = 394) by applying various measures and detection methods. A Latent Profile Analysis revealed that 45.9% of the participants showed some form of careless behavior. Excluding these participants increased the effect size in an experiment included in the survey. Based on our findings, several recommendations of easy to apply measures for assessing data quality are given.},
 author = {Florian Brühlmann and Serge Petralito and Lena F. Aeschbach and Klaus Opwis},
 doi = {https://doi.org/10.1016/j.metip.2020.100022},
 issn = {2590-2601},
 journal = {Methods in Psychology},
 keywords = {Careless responding, Crowdsourcing, Survey, Response patterns, Inattentive responding, Open answer, Latent profile analysis},
 pages = {100022},
 title = {The quality of data collected online: An investigation of careless responding in a crowdsourced sample},
 url = {http://www.sciencedirect.com/science/article/pii/S2590260120300096},
 volume = {2},
 year = {2020}
}


